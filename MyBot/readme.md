# MyBot

### Created using Langchain and GPT-Index

I have used OpenAI's LLM model here for example. But, can use other LLM models too.

#### Basic Concept
- OpenAI's LLM GPT-3 basically does in text completion.
- There are multiple version of GPT-3 only
- And we can fine tune this model to work better on some specific task or on some specific manner.
- And this is exaclty how the mighty  ChatGPT  was created.
- **********ChatGPT********** was created by fine tuning `text-davinci-003` for Q/A purpose by feeding it with custom dataset where model learnt to generate text in unique pattern.

####  What exactly is fine tuning?

- Fine tuning is nothing but addition of additional layer after pre trained modelâ€™s layer.
- It basically updates weights in pre-trained model in such way that it incline towards some specific purpose task.
- Also, while fine tuning we can use same embedding as that of pre-trained model or create embedding on our own by adding embedding layer too.
- Generally when pre-trained model is trained on huge/general dataset it is not necessary to create embedding.
